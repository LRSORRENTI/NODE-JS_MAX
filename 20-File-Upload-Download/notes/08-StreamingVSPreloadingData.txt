 
=============================
Streaming VS Pre-loading Data 
=============================

We can improve the way we serve the file from: 


exports.getInvoice = (req, res, next) => {
  const orderId = req.params.orderId;
  Order.findById(orderId)
  .then(order => {
    if(!order){
        return next(new Error('No order found'));
    }
    if(order.user.userId.toString() !== req.user._id.toString()){
        // So if the above is true, if it's not equal then return
      return next(new Error('Unauthorized Access'))
    }
    const invoiceName = 'invoice-' + orderId + '.pdf';
    const invoicePath = path.join('data', 'invoices', invoiceName)
  
  fs.readFile(invoicePath, (error, data) => {
    if(error){
      return next(error)
    }
    res.setHeader('Content-Type', 'application/pdf' );
    res.setHeader('Content-Disposition', 'inline; filename="' + invoiceName + '"');
  
  res.send(data);
  });
 })
 .catch(err => {
  console.log(err)
 })
}

When we call res.send(data) we send that file, and 
for small files that works, but if we read the file,
fs.readfile()

Node will enter the entire file into memory then 
return it with the response, this means that the 
response will take a long time, and potentially 
catalyzing a memory overflow

This is due to the fact that the fs.readFile method 
reads the entire file into memory, with big files, 
it will take some time 

For files we know for certain are tiny, it's fine 
but for large or unknown sizes, it's not ideal 

Instead we STREAM the response data, which is what 
we'll implment now 


    const invoiceName = 'invoice-' + orderId + '.pdf';
    const invoicePath = path.join('data', 'invoices', invoiceName)
  
  // fs.readFile(invoicePath, (error, data) => {
  //   if(error){
  //     return next(error)
  //   }
  //   res.setHeader('Content-Type', 'application/pdf' );
  //   res.setHeader('Content-Disposition', 'inline; filename="' + invoiceName + '"');
  
  // res.send(data);
  // });
  // Instead of reading the entire file, which if it's a 
  // large file will take a lot of time, we'll instead 
  // stream it

  const file = fs.createReadStream(invoicePath);
// now node can read stream step by step in chunnks

res.setHeader('Content-Type', 'application/pdf');
res.setHeader('Content-Disposition', 'inline; filename="' + invoiceName + '"');
file.pipe(res);
// And we'll use the pipe method, which can pipe data that's 
//  read into my response object, we can use read streams 
// to pipe into writable streams 

// Not every object is writable, but the response 
// object is 

// Once we do this the response will be streamed to 
// the browser step by step, for large files this 
// is a bonus, because node doesn't then need to 
// pre-load all the data in memory like in the 
// readFile method, instead it streams the large 
// data on the fly

// And the most it needs to store is one chunk of 
// data, again we're back to the beginning, streams 
// and buffers, chunks are what we work with, and 
// buffers allow access to the chunks 

 })
 .catch(err => {
  console.log(err)
 })
}